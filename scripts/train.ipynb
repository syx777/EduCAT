{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "import CAT\n",
    "import json\n",
    "import logging\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setuplogger():\n",
    "    root = logging.getLogger()\n",
    "    root.setLevel(logging.INFO)\n",
    "    handler = logging.StreamHandler(sys.stdout)\n",
    "    handler.setLevel(logging.INFO)\n",
    "    formatter = logging.Formatter(\"[%(levelname)s %(asctime)s] %(message)s\")\n",
    "    handler.setFormatter(formatter)\n",
    "    root.addHandler(handler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "setuplogger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose dataset here\n",
    "dataset = 'assistment'\n",
    "# modify config here\n",
    "config = {\n",
    "    'learning_rate': 0.002,\n",
    "    'batch_size': 2048,\n",
    "    'num_epochs': 10,\n",
    "    'num_dim': 10, # for IRT or MIRT\n",
    "    'device': 'cpu',\n",
    "    # for NeuralCD\n",
    "    'prednet_len1': 128,\n",
    "    'prednet_len2': 64,\n",
    "    'betas':(0.9, 0.999),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read datasets\n",
    "train_triplets = pd.read_csv(f'./dataset/train_triples.csv', encoding='utf-8').to_records(index=False)\n",
    "concept_map = json.load(open(f'./dataset/concept_map.json', 'r'))\n",
    "concept_map = {int(k):v for k,v in concept_map.items()}\n",
    "metadata = json.load(open(f'./dataset/metadata.json', 'r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = CAT.dataset.TrainDataset(train_triplets, concept_map,\n",
    "                                      metadata['num_train_students'], \n",
    "                                      metadata['num_questions'], \n",
    "                                      metadata['num_concepts'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO 2024-06-08 17:47:52,872] train on cpu\n",
      "[INFO 2024-06-08 17:47:52,872] train on cpu\n",
      "[INFO 2024-06-08 17:47:52,933] Epoch [1] Batch [0]: loss=inf\n",
      "[INFO 2024-06-08 17:47:52,933] Epoch [1] Batch [0]: loss=inf\n",
      "[INFO 2024-06-08 17:47:53,584] Epoch [1] Batch [10]: loss=0.76193\n",
      "[INFO 2024-06-08 17:47:53,584] Epoch [1] Batch [10]: loss=0.76193\n",
      "[INFO 2024-06-08 17:47:54,126] Epoch [1] Batch [20]: loss=0.72686\n",
      "[INFO 2024-06-08 17:47:54,126] Epoch [1] Batch [20]: loss=0.72686\n",
      "[INFO 2024-06-08 17:47:54,679] Epoch [1] Batch [30]: loss=0.71491\n",
      "[INFO 2024-06-08 17:47:54,679] Epoch [1] Batch [30]: loss=0.71491\n",
      "[INFO 2024-06-08 17:47:55,232] Epoch [1] Batch [40]: loss=0.70873\n",
      "[INFO 2024-06-08 17:47:55,232] Epoch [1] Batch [40]: loss=0.70873\n",
      "[INFO 2024-06-08 17:47:55,802] Epoch [1] Batch [50]: loss=0.70485\n",
      "[INFO 2024-06-08 17:47:55,802] Epoch [1] Batch [50]: loss=0.70485\n",
      "[INFO 2024-06-08 17:47:56,359] Epoch [1] Batch [60]: loss=0.70213\n",
      "[INFO 2024-06-08 17:47:56,359] Epoch [1] Batch [60]: loss=0.70213\n",
      "[INFO 2024-06-08 17:47:56,588] Epoch [2] Batch [0]: loss=inf\n",
      "[INFO 2024-06-08 17:47:56,588] Epoch [2] Batch [0]: loss=inf\n",
      "[INFO 2024-06-08 17:47:57,270] Epoch [2] Batch [10]: loss=0.75388\n",
      "[INFO 2024-06-08 17:47:57,270] Epoch [2] Batch [10]: loss=0.75388\n",
      "[INFO 2024-06-08 17:47:57,823] Epoch [2] Batch [20]: loss=0.71908\n",
      "[INFO 2024-06-08 17:47:57,823] Epoch [2] Batch [20]: loss=0.71908\n",
      "[INFO 2024-06-08 17:47:58,391] Epoch [2] Batch [30]: loss=0.70722\n",
      "[INFO 2024-06-08 17:47:58,391] Epoch [2] Batch [30]: loss=0.70722\n",
      "[INFO 2024-06-08 17:47:58,978] Epoch [2] Batch [40]: loss=0.70114\n",
      "[INFO 2024-06-08 17:47:58,978] Epoch [2] Batch [40]: loss=0.70114\n",
      "[INFO 2024-06-08 17:47:59,547] Epoch [2] Batch [50]: loss=0.69730\n",
      "[INFO 2024-06-08 17:47:59,547] Epoch [2] Batch [50]: loss=0.69730\n",
      "[INFO 2024-06-08 17:48:00,112] Epoch [2] Batch [60]: loss=0.69458\n",
      "[INFO 2024-06-08 17:48:00,112] Epoch [2] Batch [60]: loss=0.69458\n",
      "[INFO 2024-06-08 17:48:00,336] Epoch [3] Batch [0]: loss=inf\n",
      "[INFO 2024-06-08 17:48:00,336] Epoch [3] Batch [0]: loss=inf\n",
      "[INFO 2024-06-08 17:48:00,905] Epoch [3] Batch [10]: loss=0.74545\n",
      "[INFO 2024-06-08 17:48:00,905] Epoch [3] Batch [10]: loss=0.74545\n",
      "[INFO 2024-06-08 17:48:01,592] Epoch [3] Batch [20]: loss=0.71112\n",
      "[INFO 2024-06-08 17:48:01,592] Epoch [3] Batch [20]: loss=0.71112\n",
      "[INFO 2024-06-08 17:48:02,181] Epoch [3] Batch [30]: loss=0.69930\n",
      "[INFO 2024-06-08 17:48:02,181] Epoch [3] Batch [30]: loss=0.69930\n",
      "[INFO 2024-06-08 17:48:02,777] Epoch [3] Batch [40]: loss=0.69320\n",
      "[INFO 2024-06-08 17:48:02,777] Epoch [3] Batch [40]: loss=0.69320\n",
      "[INFO 2024-06-08 17:48:03,365] Epoch [3] Batch [50]: loss=0.68949\n",
      "[INFO 2024-06-08 17:48:03,365] Epoch [3] Batch [50]: loss=0.68949\n",
      "[INFO 2024-06-08 17:48:03,964] Epoch [3] Batch [60]: loss=0.68680\n",
      "[INFO 2024-06-08 17:48:03,964] Epoch [3] Batch [60]: loss=0.68680\n",
      "[INFO 2024-06-08 17:48:04,211] Epoch [4] Batch [0]: loss=inf\n",
      "[INFO 2024-06-08 17:48:04,211] Epoch [4] Batch [0]: loss=inf\n",
      "[INFO 2024-06-08 17:48:04,796] Epoch [4] Batch [10]: loss=0.73646\n",
      "[INFO 2024-06-08 17:48:04,796] Epoch [4] Batch [10]: loss=0.73646\n",
      "[INFO 2024-06-08 17:48:05,482] Epoch [4] Batch [20]: loss=0.70237\n",
      "[INFO 2024-06-08 17:48:05,482] Epoch [4] Batch [20]: loss=0.70237\n",
      "[INFO 2024-06-08 17:48:06,085] Epoch [4] Batch [30]: loss=0.69079\n",
      "[INFO 2024-06-08 17:48:06,085] Epoch [4] Batch [30]: loss=0.69079\n",
      "[INFO 2024-06-08 17:48:06,668] Epoch [4] Batch [40]: loss=0.68471\n",
      "[INFO 2024-06-08 17:48:06,668] Epoch [4] Batch [40]: loss=0.68471\n",
      "[INFO 2024-06-08 17:48:07,272] Epoch [4] Batch [50]: loss=0.68088\n",
      "[INFO 2024-06-08 17:48:07,272] Epoch [4] Batch [50]: loss=0.68088\n",
      "[INFO 2024-06-08 17:48:07,884] Epoch [4] Batch [60]: loss=0.67811\n",
      "[INFO 2024-06-08 17:48:07,884] Epoch [4] Batch [60]: loss=0.67811\n",
      "[INFO 2024-06-08 17:48:08,124] Epoch [5] Batch [0]: loss=inf\n",
      "[INFO 2024-06-08 17:48:08,124] Epoch [5] Batch [0]: loss=inf\n",
      "[INFO 2024-06-08 17:48:08,735] Epoch [5] Batch [10]: loss=0.72676\n",
      "[INFO 2024-06-08 17:48:08,735] Epoch [5] Batch [10]: loss=0.72676\n",
      "[INFO 2024-06-08 17:48:09,433] Epoch [5] Batch [20]: loss=0.69307\n",
      "[INFO 2024-06-08 17:48:09,433] Epoch [5] Batch [20]: loss=0.69307\n",
      "[INFO 2024-06-08 17:48:10,011] Epoch [5] Batch [30]: loss=0.68129\n",
      "[INFO 2024-06-08 17:48:10,011] Epoch [5] Batch [30]: loss=0.68129\n",
      "[INFO 2024-06-08 17:48:10,617] Epoch [5] Batch [40]: loss=0.67522\n",
      "[INFO 2024-06-08 17:48:10,617] Epoch [5] Batch [40]: loss=0.67522\n",
      "[INFO 2024-06-08 17:48:11,222] Epoch [5] Batch [50]: loss=0.67130\n",
      "[INFO 2024-06-08 17:48:11,222] Epoch [5] Batch [50]: loss=0.67130\n",
      "[INFO 2024-06-08 17:48:11,797] Epoch [5] Batch [60]: loss=0.66875\n",
      "[INFO 2024-06-08 17:48:11,797] Epoch [5] Batch [60]: loss=0.66875\n",
      "[INFO 2024-06-08 17:48:12,032] Epoch [6] Batch [0]: loss=inf\n",
      "[INFO 2024-06-08 17:48:12,032] Epoch [6] Batch [0]: loss=inf\n",
      "[INFO 2024-06-08 17:48:12,611] Epoch [6] Batch [10]: loss=0.71581\n",
      "[INFO 2024-06-08 17:48:12,611] Epoch [6] Batch [10]: loss=0.71581\n",
      "[INFO 2024-06-08 17:48:13,192] Epoch [6] Batch [20]: loss=0.68232\n",
      "[INFO 2024-06-08 17:48:13,192] Epoch [6] Batch [20]: loss=0.68232\n",
      "[INFO 2024-06-08 17:48:13,893] Epoch [6] Batch [30]: loss=0.67119\n",
      "[INFO 2024-06-08 17:48:13,893] Epoch [6] Batch [30]: loss=0.67119\n",
      "[INFO 2024-06-08 17:48:14,498] Epoch [6] Batch [40]: loss=0.66522\n",
      "[INFO 2024-06-08 17:48:14,498] Epoch [6] Batch [40]: loss=0.66522\n",
      "[INFO 2024-06-08 17:48:15,110] Epoch [6] Batch [50]: loss=0.66129\n",
      "[INFO 2024-06-08 17:48:15,110] Epoch [6] Batch [50]: loss=0.66129\n",
      "[INFO 2024-06-08 17:48:15,720] Epoch [6] Batch [60]: loss=0.65869\n",
      "[INFO 2024-06-08 17:48:15,720] Epoch [6] Batch [60]: loss=0.65869\n",
      "[INFO 2024-06-08 17:48:15,950] Epoch [7] Batch [0]: loss=inf\n",
      "[INFO 2024-06-08 17:48:15,950] Epoch [7] Batch [0]: loss=inf\n",
      "[INFO 2024-06-08 17:48:16,534] Epoch [7] Batch [10]: loss=0.70404\n",
      "[INFO 2024-06-08 17:48:16,534] Epoch [7] Batch [10]: loss=0.70404\n",
      "[INFO 2024-06-08 17:48:17,109] Epoch [7] Batch [20]: loss=0.67138\n",
      "[INFO 2024-06-08 17:48:17,109] Epoch [7] Batch [20]: loss=0.67138\n",
      "[INFO 2024-06-08 17:48:17,806] Epoch [7] Batch [30]: loss=0.66002\n",
      "[INFO 2024-06-08 17:48:17,806] Epoch [7] Batch [30]: loss=0.66002\n",
      "[INFO 2024-06-08 17:48:18,393] Epoch [7] Batch [40]: loss=0.65437\n",
      "[INFO 2024-06-08 17:48:18,393] Epoch [7] Batch [40]: loss=0.65437\n",
      "[INFO 2024-06-08 17:48:18,981] Epoch [7] Batch [50]: loss=0.65079\n",
      "[INFO 2024-06-08 17:48:18,981] Epoch [7] Batch [50]: loss=0.65079\n",
      "[INFO 2024-06-08 17:48:19,582] Epoch [7] Batch [60]: loss=0.64818\n",
      "[INFO 2024-06-08 17:48:19,582] Epoch [7] Batch [60]: loss=0.64818\n",
      "[INFO 2024-06-08 17:48:19,822] Epoch [8] Batch [0]: loss=inf\n",
      "[INFO 2024-06-08 17:48:19,822] Epoch [8] Batch [0]: loss=inf\n",
      "[INFO 2024-06-08 17:48:20,410] Epoch [8] Batch [10]: loss=0.69309\n",
      "[INFO 2024-06-08 17:48:20,410] Epoch [8] Batch [10]: loss=0.69309\n",
      "[INFO 2024-06-08 17:48:21,010] Epoch [8] Batch [20]: loss=0.66134\n",
      "[INFO 2024-06-08 17:48:21,010] Epoch [8] Batch [20]: loss=0.66134\n",
      "[INFO 2024-06-08 17:48:21,725] Epoch [8] Batch [30]: loss=0.64961\n",
      "[INFO 2024-06-08 17:48:21,725] Epoch [8] Batch [30]: loss=0.64961\n",
      "[INFO 2024-06-08 17:48:22,321] Epoch [8] Batch [40]: loss=0.64369\n",
      "[INFO 2024-06-08 17:48:22,321] Epoch [8] Batch [40]: loss=0.64369\n",
      "[INFO 2024-06-08 17:48:22,919] Epoch [8] Batch [50]: loss=0.64028\n",
      "[INFO 2024-06-08 17:48:22,919] Epoch [8] Batch [50]: loss=0.64028\n",
      "[INFO 2024-06-08 17:48:23,514] Epoch [8] Batch [60]: loss=0.63759\n",
      "[INFO 2024-06-08 17:48:23,514] Epoch [8] Batch [60]: loss=0.63759\n",
      "[INFO 2024-06-08 17:48:23,750] Epoch [9] Batch [0]: loss=inf\n",
      "[INFO 2024-06-08 17:48:23,750] Epoch [9] Batch [0]: loss=inf\n",
      "[INFO 2024-06-08 17:48:24,344] Epoch [9] Batch [10]: loss=0.68184\n",
      "[INFO 2024-06-08 17:48:24,344] Epoch [9] Batch [10]: loss=0.68184\n",
      "[INFO 2024-06-08 17:48:24,940] Epoch [9] Batch [20]: loss=0.65004\n",
      "[INFO 2024-06-08 17:48:24,940] Epoch [9] Batch [20]: loss=0.65004\n",
      "[INFO 2024-06-08 17:48:25,525] Epoch [9] Batch [30]: loss=0.63936\n",
      "[INFO 2024-06-08 17:48:25,525] Epoch [9] Batch [30]: loss=0.63936\n",
      "[INFO 2024-06-08 17:48:26,229] Epoch [9] Batch [40]: loss=0.63363\n",
      "[INFO 2024-06-08 17:48:26,229] Epoch [9] Batch [40]: loss=0.63363\n",
      "[INFO 2024-06-08 17:48:26,806] Epoch [9] Batch [50]: loss=0.62970\n",
      "[INFO 2024-06-08 17:48:26,806] Epoch [9] Batch [50]: loss=0.62970\n",
      "[INFO 2024-06-08 17:48:27,378] Epoch [9] Batch [60]: loss=0.62724\n",
      "[INFO 2024-06-08 17:48:27,378] Epoch [9] Batch [60]: loss=0.62724\n",
      "[INFO 2024-06-08 17:48:27,612] Epoch [10] Batch [0]: loss=inf\n",
      "[INFO 2024-06-08 17:48:27,612] Epoch [10] Batch [0]: loss=inf\n",
      "[INFO 2024-06-08 17:48:28,173] Epoch [10] Batch [10]: loss=0.67117\n",
      "[INFO 2024-06-08 17:48:28,173] Epoch [10] Batch [10]: loss=0.67117\n",
      "[INFO 2024-06-08 17:48:28,768] Epoch [10] Batch [20]: loss=0.63896\n",
      "[INFO 2024-06-08 17:48:28,768] Epoch [10] Batch [20]: loss=0.63896\n",
      "[INFO 2024-06-08 17:48:29,350] Epoch [10] Batch [30]: loss=0.62850\n",
      "[INFO 2024-06-08 17:48:29,350] Epoch [10] Batch [30]: loss=0.62850\n",
      "[INFO 2024-06-08 17:48:30,064] Epoch [10] Batch [40]: loss=0.62304\n",
      "[INFO 2024-06-08 17:48:30,064] Epoch [10] Batch [40]: loss=0.62304\n",
      "[INFO 2024-06-08 17:48:30,665] Epoch [10] Batch [50]: loss=0.61968\n",
      "[INFO 2024-06-08 17:48:30,665] Epoch [10] Batch [50]: loss=0.61968\n",
      "[INFO 2024-06-08 17:48:31,261] Epoch [10] Batch [60]: loss=0.61717\n",
      "[INFO 2024-06-08 17:48:31,261] Epoch [10] Batch [60]: loss=0.61717\n"
     ]
    }
   ],
   "source": [
    "# define model here\n",
    "model = CAT.model.IRTModel(**config)\n",
    "# train model\n",
    "model.init_model(train_data)\n",
    "model.train(train_data, log_step=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "model.adaptest_save('../ckpt/mirt.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
